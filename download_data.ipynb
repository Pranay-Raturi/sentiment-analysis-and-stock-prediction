{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download required data from yahoo finance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "from twscrape import API, gather"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download the stock data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data added to stock_data folder\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# tickers is the list of stock tickers of 10 companies listed on the NYSE\n",
    "tickers = [\"AAPL\", \"AMZN\", \"MSFT\", \"GOOG\", \"NVDA\", \"NFLX\", \"DIS\", \"TSLA\", \"LLY\", \"BA\"]\n",
    "start_date = \"2019-01-01\"\n",
    "end_date = \"2023-12-31\"\n",
    "for ticker in tickers:\n",
    "    # download the data from Yahoo Finance\n",
    "    data = yf.download(ticker, start=start_date, end=end_date) \n",
    "    # convert the downloaded data into csv files\n",
    "    data.to_csv(\"stock_data/{ticker}_{start_date[:4]}-{end_date[:4]}\")\n",
    "print(\"Data added to stock_data folder\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## twitter data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "api = API()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def scrape_tweets(company, start_date, end_date):\n",
    "    \n",
    "    data = []  #create an empty list to be used to store the search results\n",
    "    \n",
    "    #define the search query. Include start date and end date\n",
    "    q = f\"${company} until:{end_date} since:{start_date} lang:en\" \n",
    "    save_to_file = f\"twitter_data/{company}_{start_date}-{end_date}\"\n",
    "    \n",
    "    async for tweet in api.search(q, limit=300000): #iterate over the search results\n",
    "        c = [tweet.id, tweet.date, tweet.rawContent, tweet.likeCount, tweet.retweetCount, tweet.user.location] #list of attributes to return \n",
    "        data.append(c)  #add each new list of attributes to 'data'\n",
    "    \n",
    "    df = pd.DataFrame(data, columns=['Tweet_ID', 'Time_Created', 'Text', 'Likes', 'Retweets', 'Location']) #convert the list to a dataframe\n",
    "    df.to_csv(save_to_file, index = False) #save to a chosen directory on the computer\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-04-21 20:13:46.611\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mtwscrape.queue_client\u001b[0m:\u001b[36m_check_rep\u001b[0m:\u001b[36m157\u001b[0m - \u001b[33m\u001b[1mBan detected: 200 - 49/50 - testid1106 - (326) Authorization: Denied by access control: To protect our users from spam and other malicious activity, this account is temporarily locked. Please log in to https://twitter.com to unlock your account.\u001b[0m\n",
      "\u001b[32m2024-04-21 20:15:12.025\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtwscrape.accounts_pool\u001b[0m:\u001b[36mget_for_queue_or_wait\u001b[0m:\u001b[36m275\u001b[0m - \u001b[1mNo account available for queue \"SearchTimeline\". Next available at 20:27:12\u001b[0m\n",
      "\u001b[32m2024-04-21 20:17:27.429\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtwscrape.accounts_pool\u001b[0m:\u001b[36mget_for_queue_or_wait\u001b[0m:\u001b[36m281\u001b[0m - \u001b[1mContinuing with account testid1106 on queue SearchTimeline\u001b[0m\n",
      "\u001b[32m2024-04-21 20:18:06.769\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtwscrape.accounts_pool\u001b[0m:\u001b[36mget_for_queue_or_wait\u001b[0m:\u001b[36m275\u001b[0m - \u001b[1mNo account available for queue \"SearchTimeline\". Next available at 20:27:12\u001b[0m\n",
      "\u001b[32m2024-04-21 20:27:13.258\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtwscrape.accounts_pool\u001b[0m:\u001b[36mget_for_queue_or_wait\u001b[0m:\u001b[36m281\u001b[0m - \u001b[1mContinuing with account divij_jasuja on queue SearchTimeline\u001b[0m\n",
      "\u001b[32m2024-04-21 20:27:58.720\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtwscrape.accounts_pool\u001b[0m:\u001b[36mget_for_queue_or_wait\u001b[0m:\u001b[36m275\u001b[0m - \u001b[1mNo account available for queue \"SearchTimeline\". Next available at 20:28:00\u001b[0m\n",
      "\u001b[32m2024-04-21 20:28:03.742\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtwscrape.accounts_pool\u001b[0m:\u001b[36mget_for_queue_or_wait\u001b[0m:\u001b[36m281\u001b[0m - \u001b[1mContinuing with account PranayRaturi on queue SearchTimeline\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweet_ID</th>\n",
       "      <th>Time_Created</th>\n",
       "      <th>Text</th>\n",
       "      <th>Likes</th>\n",
       "      <th>Retweets</th>\n",
       "      <th>Location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1748495382944895066</td>\n",
       "      <td>2024-01-19 23:59:19+00:00</td>\n",
       "      <td>Chip names, chip games! Which stock has a high...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Pittsburgh, PA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1748495348174369118</td>\n",
       "      <td>2024-01-19 23:59:11+00:00</td>\n",
       "      <td>Best place for day trading, swing trading, sto...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1748495299641848185</td>\n",
       "      <td>2024-01-19 23:58:59+00:00</td>\n",
       "      <td>Celebrate with us these amazing profits on $NV...</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>Texas, USA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1748495275553960360</td>\n",
       "      <td>2024-01-19 23:58:53+00:00</td>\n",
       "      <td>@BradMunchen Talking ‚Äúdistressed‚Äù I think is e...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Canada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1748495072960631288</td>\n",
       "      <td>2024-01-19 23:58:05+00:00</td>\n",
       "      <td>First Majestic Stock (NYSE:AG) Will Shine in a...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>USA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6466</th>\n",
       "      <td>1747775029905924363</td>\n",
       "      <td>2024-01-18 00:16:53+00:00</td>\n",
       "      <td>Canceled Cybertruck which is DEAD, and placed ...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>Portugal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6467</th>\n",
       "      <td>1747771556976025982</td>\n",
       "      <td>2024-01-18 00:03:05+00:00</td>\n",
       "      <td>üö® Quote of the Day üö® ‚ÄúThe pessimist sees diffi...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Makin Money</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6468</th>\n",
       "      <td>1747771417226080466</td>\n",
       "      <td>2024-01-18 00:02:32+00:00</td>\n",
       "      <td>Thurs Jan 18 Watchlist\\n\\n$SPY C &gt; 474, 467 / ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6469</th>\n",
       "      <td>1747771167883059323</td>\n",
       "      <td>2024-01-18 00:01:33+00:00</td>\n",
       "      <td>@The_AI_Investor Clearly that person has been ...</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>Boston | Cape Cod</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6470</th>\n",
       "      <td>1747771009418334367</td>\n",
       "      <td>2024-01-18 00:00:55+00:00</td>\n",
       "      <td>@MartyChargin $AMD $NVDA standouts. Leaders ke...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6471 rows √ó 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Tweet_ID              Time_Created  \\\n",
       "0     1748495382944895066 2024-01-19 23:59:19+00:00   \n",
       "1     1748495348174369118 2024-01-19 23:59:11+00:00   \n",
       "2     1748495299641848185 2024-01-19 23:58:59+00:00   \n",
       "3     1748495275553960360 2024-01-19 23:58:53+00:00   \n",
       "4     1748495072960631288 2024-01-19 23:58:05+00:00   \n",
       "...                   ...                       ...   \n",
       "6466  1747775029905924363 2024-01-18 00:16:53+00:00   \n",
       "6467  1747771556976025982 2024-01-18 00:03:05+00:00   \n",
       "6468  1747771417226080466 2024-01-18 00:02:32+00:00   \n",
       "6469  1747771167883059323 2024-01-18 00:01:33+00:00   \n",
       "6470  1747771009418334367 2024-01-18 00:00:55+00:00   \n",
       "\n",
       "                                                   Text  Likes  Retweets  \\\n",
       "0     Chip names, chip games! Which stock has a high...      0         0   \n",
       "1     Best place for day trading, swing trading, sto...      0         0   \n",
       "2     Celebrate with us these amazing profits on $NV...     11         2   \n",
       "3     @BradMunchen Talking ‚Äúdistressed‚Äù I think is e...      0         0   \n",
       "4     First Majestic Stock (NYSE:AG) Will Shine in a...      2         0   \n",
       "...                                                 ...    ...       ...   \n",
       "6466  Canceled Cybertruck which is DEAD, and placed ...      2         0   \n",
       "6467  üö® Quote of the Day üö® ‚ÄúThe pessimist sees diffi...      1         0   \n",
       "6468  Thurs Jan 18 Watchlist\\n\\n$SPY C > 474, 467 / ...      0         0   \n",
       "6469  @The_AI_Investor Clearly that person has been ...      7         0   \n",
       "6470  @MartyChargin $AMD $NVDA standouts. Leaders ke...      0         0   \n",
       "\n",
       "                Location  \n",
       "0         Pittsburgh, PA  \n",
       "1                         \n",
       "2             Texas, USA  \n",
       "3                 Canada  \n",
       "4                    USA  \n",
       "...                  ...  \n",
       "6466            Portugal  \n",
       "6467         Makin Money  \n",
       "6468                      \n",
       "6469  Boston | Cape Cod   \n",
       "6470                      \n",
       "\n",
       "[6471 rows x 6 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nvidia_tweets = await scrape_tweets(\"NVDA\", \"2024-01-18\", \"2024-01-20\")\n",
    "nvidia_tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Time_Created\n",
       "2024-01-19    3287\n",
       "2024-01-18    2945\n",
       "2024-01-17      64\n",
       "2024-01-16      27\n",
       "2024-01-09      20\n",
       "2024-01-08      18\n",
       "2024-01-11      13\n",
       "2024-01-10       9\n",
       "2024-01-12       8\n",
       "2024-01-15       5\n",
       "2024-01-05       4\n",
       "2024-01-14       4\n",
       "2023-05-31       3\n",
       "2023-12-29       3\n",
       "2023-12-21       3\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datetime import date\n",
    "# nvidia_tweets[nvidia_tweets['Time_Created'] < date(2024, 1, 8) or nvidia_tweets['Time_Created'] > date(2024, 1, 15)]\n",
    "# pd.to_datetime(nvidia_tweets['Time_Created']).dt.date\n",
    "# nvidia_tweets = pd.read_csv(\"twitter_data/NVDA_2024-01-08-2024-01-15\")\n",
    "nvidia_tweets['Time_Created'] = pd.to_datetime(nvidia_tweets['Time_Created']).dt.date\n",
    "nvidia_tweets['Time_Created'].sort_values().value_counts()[:15]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
